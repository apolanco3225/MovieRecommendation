{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXIMwrcdEzn0AcRa7CzU3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apolanco3225/MovieRecommendation/blob/main/ModelBaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jaqq_v59U_hL",
        "outputId": "d149c24a-fc5f-4c51-8ccc-48fc9b3644d5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# install graphml dl libraries\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!git clone https://github.com/pmaldonado/cs224w-project-data.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Reading\n"
      ],
      "metadata": {
        "id": "LElCCVdElmWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import degree"
      ],
      "metadata": {
        "id": "d86XQtR7XR8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "pm57DuO4kXLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"data/ml-100k/u.data\",\n",
        "    sep=\"\\t\",\n",
        "    names = [\"user_id\", \"movie_id\", \"rate\" ,\"timestamp\"]\n",
        ")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "MYGLWkL5lDVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "Tuf0xgsIx7lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data dimensions. Samples: {data.shape[0]} and Columns: {data.shape[1]}\")\n",
        "print(f\"Total number of users: {len(data.user_id.unique())}\")\n",
        "print(f\"Total number of movies: {len(data.movie_id.unique())}\")\n",
        "print(f\"Rating distribution:\\n{data.rate.value_counts()[[1, 2, 3, 4, 5]]}\",)"
      ],
      "metadata": {
        "id": "zsAe-hMsmeZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter movies with good rates"
      ],
      "metadata": {
        "id": "N0DgGMm2AfmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.query(\"rate >= 3\")"
      ],
      "metadata": {
        "id": "OvH6lMx3nW54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data dimensions. Samples: {data.shape[0]} and Columns: {data.shape[1]}\")\n",
        "print(f\"Total number of users: {len(data.user_id.unique())}\")\n",
        "print(f\"Total number of movies: {len(data.movie_id.unique())}\")\n",
        "print(f\"Rating distribution:\\n{data.rate.value_counts()[[3, 4, 5]]}\",)"
      ],
      "metadata": {
        "id": "LuZyueA0nW8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Partition"
      ],
      "metadata": {
        "id": "zeCZmtcryGFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)\n",
        "print(f\"Length train data: {len(train_data)}\")\n",
        "print(f\"Length test data: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "k1qXXxz5n3ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.reset_index()\n",
        "test_data = test_data.reset_index()"
      ],
      "metadata": {
        "id": "EwlYKdV5Ffn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Encoding"
      ],
      "metadata": {
        "id": "QWEpkTnIzxzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "unCSktv2ve9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect users and movies that appear both in training and testing sets:"
      ],
      "metadata": {
        "id": "4E8tW5vEyaan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_mask = test_data.user_id.isin(train_data.user_id.unique())\n",
        "movie_mask = test_data.movie_id.isin(train_data.movie_id.unique())\n",
        "user_and_movie_mask = (user_mask & movie_mask)"
      ],
      "metadata": {
        "id": "9CLf3mBsxYc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter test dataset with users and movies that are present in training:"
      ],
      "metadata": {
        "id": "a1fVds0bygnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data[user_and_movie_mask]"
      ],
      "metadata": {
        "id": "ryGb4HZAxYe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding users and movies in training set:"
      ],
      "metadata": {
        "id": "Erb7eR2l0D5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.loc[:, \"user_id\"] = user_encoder.fit_transform(train_data.user_id)\n",
        "train_data.loc[:, \"movie_id\"] = movie_encoder.fit_transform(train_data.movie_id)"
      ],
      "metadata": {
        "id": "lL9-UhOO0ENJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding of users and movies from testing set using encoders from training set."
      ],
      "metadata": {
        "id": "y_DJLUVqzdW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.loc[:, \"user_id\"] = user_encoder.transform(test_data.user_id)\n",
        "test_data.loc[:, \"movie_id\"] = movie_encoder.transform(test_data.movie_id)"
      ],
      "metadata": {
        "id": "sbH98vX1y7lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing\n"
      ],
      "metadata": {
        "id": "W6Qx68xL3PQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(train_data.user_id.unique())\n",
        "num_movies = len(train_data.movie_id.unique())\n",
        "\n",
        "print(f\"Unique users: {num_users} Unique movies: {num_movies}\")"
      ],
      "metadata": {
        "id": "WYkho6oiy-Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_nodes = torch.LongTensor(train_data.user_id)\n",
        "# add the num of users to the items value so both sets\n",
        "# won't have node ids that overlap\n",
        "movies_nodes = torch.LongTensor(train_data.movie_id) + num_users"
      ],
      "metadata": {
        "id": "8hENa7Zip9He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_edge_connections = torch.stack(\n",
        "    (\n",
        "        torch.cat([users_nodes, movies_nodes]),\n",
        "        torch.cat([movies_nodes, users_nodes])\n",
        "    )\n",
        ").to(device)\n",
        "\n",
        "print(train_edge_connections)"
      ],
      "metadata": {
        "id": "uh0ZTtbdp9M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition\n"
      ],
      "metadata": {
        "id": "54NMm9iGARP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "\n",
        "import random\n",
        "\n",
        "def data_loader(data, batch_size, n_usr, n_itm):\n",
        "\n",
        "    def sample_neg(x):\n",
        "        while True:\n",
        "            neg_id = random.randint(0, n_itm - 1)\n",
        "            if neg_id not in x:\n",
        "                return neg_id\n",
        "\n",
        "    interected_items_df = data.groupby('user_id')['movie_id'].apply(list).reset_index()\n",
        "    indices = [x for x in range(n_usr)]\n",
        "\n",
        "    if n_usr < batch_size:\n",
        "        users = [random.choice(indices) for _ in range(batch_size)]\n",
        "    else:\n",
        "        users = random.sample(indices, batch_size)\n",
        "    users.sort()\n",
        "    users_df = pd.DataFrame(users,columns = ['users'])\n",
        "\n",
        "    interected_items_df = pd.merge(interected_items_df, users_df, how = 'right', left_on = 'user_id', right_on = 'users')\n",
        "    pos_items = interected_items_df['movie_id'].apply(lambda x : random.choice(x)).values\n",
        "    neg_items = interected_items_df['movie_id'].apply(lambda x: sample_neg(x)).values\n",
        "\n",
        "    return (\n",
        "        torch.LongTensor(list(users)).to(device),\n",
        "        torch.LongTensor(list(pos_items)).to(device) + n_usr,\n",
        "        torch.LongTensor(list(neg_items)).to(device) + n_usr\n",
        "    )\n",
        "\n",
        "data_loader(train_data, 16, num_users, num_movies)"
      ],
      "metadata": {
        "id": "H-N4mTtw7oDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCNConv(MessagePassing):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(aggr='add')\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # Compute normalization\n",
        "    from_, to_ = edge_index\n",
        "    deg = degree(to_, x.size(0), dtype=x.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
        "\n",
        "    # Start propagating messages (no update after aggregation)\n",
        "    return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "  def message(self, x_j, norm):\n",
        "    return norm.view(-1, 1) * x_j"
      ],
      "metadata": {
        "id": "F7f4PP-lAVRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NGCFConv(MessagePassing):\n",
        "  def __init__(self, latent_dim, dropout, bias=True, **kwargs):\n",
        "    super(NGCFConv, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.lin_1 = nn.Linear(latent_dim, latent_dim, bias=bias)\n",
        "    self.lin_2 = nn.Linear(latent_dim, latent_dim, bias=bias)\n",
        "\n",
        "    self.init_parameters()\n",
        "\n",
        "\n",
        "  def init_parameters(self):\n",
        "    nn.init.xavier_uniform_(self.lin_1.weight)\n",
        "    nn.init.xavier_uniform_(self.lin_2.weight)\n",
        "\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # Compute normalization\n",
        "    from_, to_ = edge_index\n",
        "    deg = degree(to_, x.size(0), dtype=x.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
        "\n",
        "    # Start propagating messages\n",
        "    out = self.propagate(edge_index, x=(x, x), norm=norm)\n",
        "\n",
        "    # Perform update after aggregation\n",
        "    out += self.lin_1(x)\n",
        "    out = F.dropout(out, self.dropout, self.training)\n",
        "    return F.leaky_relu(out)\n",
        "\n",
        "\n",
        "  def message(self, x_j, x_i, norm):\n",
        "    return norm.view(-1, 1) * (self.lin_1(x_j) + self.lin_2(x_j * x_i))"
      ],
      "metadata": {
        "id": "BhCAQmtlAVTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecSysGNN(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      latent_dim,\n",
        "      num_layers,\n",
        "      num_users,\n",
        "      num_items,\n",
        "      model, # 'NGCF' or 'LightGCN'\n",
        "      dropout=0.1 # Only used in NGCF\n",
        "  ):\n",
        "    super(RecSysGNN, self).__init__()\n",
        "\n",
        "    assert (model == 'NGCF' or model == 'LightGCN'), \\\n",
        "        'Model must be NGCF or LightGCN'\n",
        "    self.model = model\n",
        "    self.embedding = nn.Embedding(num_users + num_items, latent_dim)\n",
        "\n",
        "    if self.model == 'NGCF':\n",
        "      self.convs = nn.ModuleList(\n",
        "        NGCFConv(latent_dim, dropout=dropout) for _ in range(num_layers)\n",
        "      )\n",
        "    else:\n",
        "      self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))\n",
        "\n",
        "    self.init_parameters()\n",
        "\n",
        "\n",
        "  def init_parameters(self):\n",
        "    if self.model == 'NGCF':\n",
        "      nn.init.xavier_uniform_(self.embedding.weight, gain=1)\n",
        "    else:\n",
        "      # Authors of LightGCN report higher results with normal initialization\n",
        "      nn.init.normal_(self.embedding.weight, std=0.1)\n",
        "\n",
        "\n",
        "  def forward(self, edge_index):\n",
        "    emb0 = self.embedding.weight\n",
        "    embs = [emb0]\n",
        "\n",
        "    emb = emb0\n",
        "    for conv in self.convs:\n",
        "      emb = conv(x=emb, edge_index=edge_index)\n",
        "      embs.append(emb)\n",
        "\n",
        "    out = (\n",
        "      torch.cat(embs, dim=-1) if self.model == 'NGCF'\n",
        "      else torch.mean(torch.stack(embs, dim=0), dim=0)\n",
        "    )\n",
        "\n",
        "    return emb0, out\n",
        "\n",
        "\n",
        "  def encode_minibatch(self, users, pos_items, neg_items, edge_index):\n",
        "    emb0, out = self(edge_index)\n",
        "    return (\n",
        "        out[users],\n",
        "        out[pos_items],\n",
        "        out[neg_items],\n",
        "        emb0[users],\n",
        "        emb0[pos_items],\n",
        "        emb0[neg_items]\n",
        "    )"
      ],
      "metadata": {
        "id": "CnbSrI7OA-Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "def compute_bpr_loss(users, users_emb, pos_emb, neg_emb, user_emb0,  pos_emb0, neg_emb0):\n",
        "  # compute loss from initial embeddings, used for regulization\n",
        "  reg_loss = (1 / 2) * (\n",
        "    user_emb0.norm().pow(2) +\n",
        "    pos_emb0.norm().pow(2)  +\n",
        "    neg_emb0.norm().pow(2)\n",
        "  ) / float(len(users))\n",
        "\n",
        "  # compute BPR loss from user, positive item, and negative item embeddings\n",
        "  pos_scores = torch.mul(users_emb, pos_emb).sum(dim=1)\n",
        "  neg_scores = torch.mul(users_emb, neg_emb).sum(dim=1)\n",
        "\n",
        "  bpr_loss = torch.mean(F.softplus(neg_scores - pos_scores))\n",
        "\n",
        "  return bpr_loss, reg_loss"
      ],
      "metadata": {
        "id": "ICo-4JKkA-Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(user_Embed_wts, item_Embed_wts, n_users, n_items, train_data, test_data, K):\n",
        "  test_user_ids = torch.LongTensor(test_data['user_id'].unique())\n",
        "  # compute the score of all user-item pairs\n",
        "  relevance_score = torch.matmul(user_Embed_wts, torch.transpose(item_Embed_wts,0, 1))\n",
        "\n",
        "  # create dense tensor of all user-item interactions\n",
        "  i = torch.stack((\n",
        "    torch.LongTensor(train_data['user_id'].values),\n",
        "    torch.LongTensor(train_data['movie_id'].values)\n",
        "  ))\n",
        "  v = torch.ones((len(train_data)), dtype=torch.float64)\n",
        "  interactions_t = torch.sparse.FloatTensor(i, v, (n_users, n_items))\\\n",
        "      .to_dense().to(device)\n",
        "\n",
        "  # mask out training user-item interactions from metric computation\n",
        "  relevance_score = torch.mul(relevance_score, (1 - interactions_t))\n",
        "\n",
        "  # compute top scoring items for each user\n",
        "  topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
        "  topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy(),columns =['top_indx_'+str(x+1) for x in range(K)])\n",
        "  topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n",
        "  topk_relevance_indices_df['top_rlvnt_itm'] = topk_relevance_indices_df[['top_indx_'+str(x+1) for x in range(K)]].values.tolist()\n",
        "  topk_relevance_indices_df = topk_relevance_indices_df[['user_ID','top_rlvnt_itm']]\n",
        "\n",
        "  # measure overlap between recommended (top-scoring) and held-out user-item\n",
        "  # interactions\n",
        "  test_interacted_items = test_data.groupby('user_id')['movie_id'].apply(list).reset_index()\n",
        "  metrics_df = pd.merge(test_interacted_items,topk_relevance_indices_df, how= 'left', left_on = 'user_id',right_on = ['user_ID'])\n",
        "  metrics_df['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in zip(metrics_df.item_id_idx, metrics_df.top_rlvnt_itm)]\n",
        "\n",
        "  metrics_df['recall'] = metrics_df.apply(lambda x : len(x['intrsctn_itm'])/len(x['item_id_idx']), axis = 1)\n",
        "  metrics_df['precision'] = metrics_df.apply(lambda x : len(x['intrsctn_itm'])/K, axis = 1)\n",
        "\n",
        "  return metrics_df['recall'].mean(), metrics_df['precision'].mean()"
      ],
      "metadata": {
        "id": "X61joE-EA-zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "rhhfqONCAW4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64\n",
        "n_layers = 3\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "DECAY = 0.0001\n",
        "LR = 0.005\n",
        "K = 20"
      ],
      "metadata": {
        "id": "1C-ubJvUBomT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(model, optimizer, train_df):\n",
        "  loss_list_epoch = []\n",
        "  bpr_loss_list_epoch = []\n",
        "  reg_loss_list_epoch = []\n",
        "\n",
        "  recall_list = []\n",
        "  precision_list = []\n",
        "\n",
        "  for epoch in tqdm(range(EPOCHS)):\n",
        "      n_batch = int(len(train_data)/BATCH_SIZE)\n",
        "\n",
        "      final_loss_list = []\n",
        "      bpr_loss_list = []\n",
        "      reg_loss_list = []\n",
        "\n",
        "      model.train()\n",
        "      for batch_idx in range(n_batch):\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          users, pos_items, neg_items = data_loader(train_df, BATCH_SIZE, num_users, num_movies)\n",
        "          users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0 = model.encode_minibatch(users, pos_items, neg_items, train_edge_connections)\n",
        "\n",
        "          bpr_loss, reg_loss = compute_bpr_loss(\n",
        "            users, users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0\n",
        "          )\n",
        "          reg_loss = DECAY * reg_loss\n",
        "          final_loss = bpr_loss + reg_loss\n",
        "\n",
        "          final_loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          final_loss_list.append(final_loss.item())\n",
        "          bpr_loss_list.append(bpr_loss.item())\n",
        "          reg_loss_list.append(reg_loss.item())\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          _, out = model(train_edge_connections)\n",
        "          final_user_Embed, final_item_Embed = torch.split(out, (num_users, num_movies))\n",
        "          test_topK_recall,  test_topK_precision = get_metrics(\n",
        "            final_user_Embed, final_item_Embed, num_users, num_movies, train_data, test_data, K\n",
        "          )\n",
        "\n",
        "      loss_list_epoch.append(round(np.mean(final_loss_list),4))\n",
        "      bpr_loss_list_epoch.append(round(np.mean(bpr_loss_list),4))\n",
        "      reg_loss_list_epoch.append(round(np.mean(reg_loss_list),4))\n",
        "\n",
        "      recall_list.append(round(test_topK_recall,4))\n",
        "      precision_list.append(round(test_topK_precision,4))\n",
        "\n",
        "  return (\n",
        "    loss_list_epoch,\n",
        "    bpr_loss_list_epoch,\n",
        "    reg_loss_list_epoch,\n",
        "    recall_list,\n",
        "    precision_list\n",
        "  )"
      ],
      "metadata": {
        "id": "EVaIcJNMBooX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgcn = RecSysGNN(\n",
        "  latent_dim=latent_dim,\n",
        "  num_layers=n_layers,\n",
        "  num_users=num_users,\n",
        "  num_items=num_movies,\n",
        "  model='LightGCN'\n",
        ")\n",
        "lightgcn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lightgcn.parameters(), lr=LR)\n",
        "print(\"Size of Learnable Embedding : \", [x.shape for x in list(lightgcn.parameters())])"
      ],
      "metadata": {
        "id": "zr0MmLVKBoqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "light_loss, light_bpr, light_reg, light_recall, light_precision = train_and_eval(\n",
        "    lightgcn,\n",
        "    optimizer,\n",
        "    train_data\n",
        ")"
      ],
      "metadata": {
        "id": "iUk6gfTRBzJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "EDmn_2aaB6fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device\n"
      ],
      "metadata": {
        "id": "z59YnxIJEWel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kxx_zS6Qecn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}